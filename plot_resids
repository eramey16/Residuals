#!/usr/bin/python
import numpy as np
import matplotlib
from matplotlib.pyplot import *
from matplotlib import rc
import matplotlib.pyplot as plt
import sys
import subprocess
import math

STARTFREQ = 1275.0
BANDWIDTH = 6.25
NCHAN = 32
PPP = 4
'''
CHANNEL = 30
FREQ = STARTFREQ+(NCHAN-CHANNEL+1)*BANDWIDTH

print FREQ
'''
#rc('text',usetex=True)
#rc('font',**{'family':'serif','serif':['Times New Roman'],'size':14})#,'weight':'bold'})
#rc('xtick',**{'labelsize':16})
#rc('ytick',**{'labelsize':16})
#rc('axes',**{'labelsize':18,'titlesize':18})
'''
if len(sys.argv)>=2:
    filename = str(sys.argv[1])
else:
    print "Require File Name"
    raise SystemExit
'''

# unmitigated guppi_0006_0000
filename1 = "/home/scratch/eramey/unmitigated/unmitigatedResiduals.dat"

# guppi_0006_0000 with channel 30 mitigated
filename2 = "/home/scratch/eramey/channel30/channel30Residuals.dat"

# guppi 0006_0000 with channel 23 mitigated
filename3 = "/home/scratch/eramey/channel23/channel23Residuals.dat"

# guppi 0006_0000 mitigated with normalization
filename4 = "/home/scratch/eramey/guppi_0006_0000_mitigated_normalized/mitigated_normalized_Resids.dat"

# all guppi 0006 files unmitigated
filename5 = "/home/scratch/eramey/guppi_56465_J1713+0747_0006_unmitigated_fold/unmitigated_Resids.dat"

# all guppi 0006 files mitigated (not normalized)
filename6 = "/home/scratch/eramey/guppi_56465_J1713+0747_0006_mitigated_fold/mitigated_Resids.dat"

# guppi 0006_0000 fully mitigated (not normalized)
filename7 = "/home/scratch/eramey/guppi_0006_0000_mitigated/mitigated_0006_0001_Resids.dat"

# guppi 0006 unmitigated (zapped)
filename8 = "/home/scratch/eramey/guppi_56465_J1713+0747_0006_unmitigated_fold/unmitigated_zapped_resids.dat"

# enter the filenames, starting with the file to compare to
filenames = [filename5, filename6, filename8]

BANDS = [327,430,820,1400,2500] #2500 is better for plotting
colors = ['m','r','g','k','b']
def getBand(freq):
    diffs=map(lambda f: abs(f-freq),BANDS)
    minindex=diffs.index(min(diffs))
    return BANDS[minindex]
'''
def epoch_averaged_error(C,var=False):
    # Stripped down version from rednoisemodel.py from the excess noise project
    N = len(C)
    UT = np.matrix(np.ones(N))
    U = UT.T
    CI = C.I
    C_E = np.dot(np.dot(UT,CI),U).I
    if var:
        return C_E[0,0]
    return np.sqrt(C_E[0,0])
 
def weighted_avg_and_std(values, weights):
	average = np.average(values, weights=weights)
	std_dev = sum([weights[i]*(values[i]-average)**2 for i in range(len(values))])
	M = 0
	for w in weights:
		if w>0:
			M+=1
	std_dev = std_dev/sum(weights)
	std_dev = np.sqrt(std_dev)
	return (average, std_dev)
'''
def avg_and_std(values):
	return (np.mean(values), np.std(values))

# get the frequency from user input
def getFreq():
	chans = "-1"
	while not checkChans(chans):
		chans = raw_input("which channel(s) would you like to evaluate? (or type 'all') - ")
		if chans=="all":
			chans = range(1, 33)
			chans = np.array(chans)
			break
		print "Channels: ", chans
		chans = chans.split(" ")
		for i in range(len(chans)):
			chans[i] = int(chans[i])
		chans = np.array(chans)
	
	freqs = []
	
	if(chans=="all"):
		for i in range(1,33):
			freqs.append(STARTFREQ+(NCHAN-i+1)*BANDWIDTH)
		print "Channels: ", range(1, 33)
	else:
		freqs = STARTFREQ+(NCHAN-chans+1)*BANDWIDTH
	return freqs, chans

'''
Return weighted sample mean and std - Michael Lam
http://en.wikipedia.org/wiki/Weighted_mean#Weighted_sample_variance
'''
def weighted_moments(series,weights,unbiased=False,harmonic=False):
    if len(series)==1:
        return series,1.0/np.sqrt(weights)
    series=np.array(series)
    weights=np.array(weights)
    weightsum=np.sum(weights)
    weightedmean = np.sum(weights*series)/weightsum
    weightedvariance = np.sum(weights*np.power(series-weightedmean,2))
    if harmonic:
        return weightedmean, harmonic_mean(1.0/weights)
    elif unbiased:
        weightsquaredsum=np.sum(np.power(weights,2))
        return weightedmean, np.sqrt(weightedvariance * weightsum / (weightsum**2 - weightsquaredsum))
    else:
        return weightedmean, np.sqrt(weightedvariance / weightsum)

# check user input for validity
def checkChans(channels):
	for x in channels:
		try:
			if int(x)<=0 or int(x)>32:
				return False
		except:
			return False
	return True

def flatten(array):
	return [x for thing in array for x in thing]

def getInfo(filename, FREQ, axes, addOn):
	print "\nFile: "+filename+"\n"
	
	#subprocess.call("print_resid > %s"%filename,shell=True)
	
	# load in the file
	mjds,freqs,resids,errs = np.loadtxt("%s"%filename,unpack=True,usecols=(0,1,2,3))
	
	# convert dates to seconds
	start = mjds[0]
	for i in range(len(mjds)):
		mjds[i]-=start
		mjds[i]*=3600*24

	# Print variance of the distribution
	ch = [[] for i in range(len(FREQ))]
	err = [[] for i in range(len(FREQ))]
	mjds2 = [[] for i in range(len(FREQ))]
	
	# append the correct residuals and errors
	for i in range(len(resids)):
		if freqs[i] in FREQ:
			index = np.where(FREQ==freqs[i])[0]
			ch[index].append(resids[i])
			err[index].append(errs[i])
			mjds2[index].append(mjds[i])
	
	'''
	print "channels ", len(ch)
	print "errors ", len(err)
	print "TOAs ", len(mjds2)
	
	for chan in ch:
		print len(chan)
	for e in err:
		print len(e)
	for t in mjds2:
		print len(t)
	
	'''
	ch = np.array(ch)
	err = np.array(err)
	mjds2 = np.array(mjds2)
	
	for e in err:
		e = np.array(e)
		e = e*(10**(-6))
	
	# average and standard deviation
	
	avg, stdDev = avg_and_std(flatten(ch))
	
	# weighted average and standard deviation
	weights = [1/w**2 for w in flatten(err)]
	w_avg, w_stdDev = weighted_moments(flatten(ch), weights, unbiased=True)
	
	print "\tAverage: {:.2e}".format(avg)
	print "\tStandard deviation: {:.2e}".format(stdDev)
	print "\tWeighted average: {:.2e}".format(w_avg)
	print "\tWeighted standard deviation: {:.2e}".format(w_stdDev)
	
	if not isinstance(axarr, np.ndarray):
		mjds2 = flatten(mjds2)
		ch = flatten(ch)
		err = flatten(err)
		matplotlib.rc('xtick', labelsize=8) 
		matplotlib.rc('ytick', labelsize=8)
		matplotlib.rc('axes', titlesize=8)
		axes.errorbar(mjds2, ch, yerr=err, linestyle='None', fmt='.', elinewidth=0.1, capthick=0.5)
		axes.set_ylim(-100, 100)
		axes.set_xlim(mjds2[0]-5, mjds2[len(mjds2)-1]+5)	
		start, end = axarr.get_ylim()
		axes.yaxis.set_ticks(np.arange(start, end+1, 25))
		axes.set_title("Channel "+str(chans[0])+" "+addOn)
	else:
		for i in range(len(axes)):
			#print "Plotting on: ", axes[i]
			matplotlib.rc('xtick', labelsize=8) 
			matplotlib.rc('ytick', labelsize=8)
			matplotlib.rc('axes', titlesize=8)
			axes[i].errorbar(mjds2[i], ch[i], yerr=err[i], linestyle='None', fmt='.', elinewidth=0.1, capthick=0.5)
			axes[i].set_ylim(-100, 100)
			axes[i].set_xlim(mjds2[i][0]-5, mjds2[i][len(mjds2 [i])-1]+5)	
			start, end = axes[i].get_ylim()
			axes[i].yaxis.set_ticks(np.arange(start, end+1, 25))
			axes[i].set_title("Channel "+str(chans[i])+" "+addOn)
			
		print ""
	
	# return the statistics
	return avg, stdDev, w_avg, w_stdDev
	
	'''
	print len(ch)
	var = np.var(ch)
	print "Variance of residuals: " + str(var)

	print "Std deviation of residuals: "+str(np.std(ch))
	
	
	# Calculate the error in the variance
	e_mean = np.sqrt(np.sum([e**2 for e in errs]))/len(errs)
	e_devs = [2*np.sqrt((resids[i]-np.mean(resids))**2 * (errs[i]**2+e_mean**2)) for i in range(len(errs))]
	e_tot = np.sqrt(np.sum([e**2 for e in e_devs]))/len(e_devs)

	C =  np.matrix(np.diag(errs**2))

	e_tot = epoch_averaged_error(C)
	
	print "Error in variance: " + str(e_tot)
	'''

# initialize stats array
stats = []
statnames = ["Average", "Standard deviation", "Weighted average", "Weighted standard deviation"]

# get the frequency from the user-defined channel
freq, chans = getFreq()
#axarr = []
# set up graphs for each channel & file
f, axarr = plt.subplots(len(freq)-2, len(filenames), sharey='row', sharex='row')
f2, axarr2 = plt.subplots(2, len(filenames), sharey = 'row', sharex='row')
axarr = np.array(axarr)
axarr2 = np.array(axarr2)

#print "axarr: ", axarr, "\n"
#print "axarr2: ", axarr2, "\n"

# get stats from all the files
for i in range(len(filenames)):
	filename = filenames[i]
	addOn = ""
	
	if "zapped" in filename:
		addOn = "zapped"
	elif "unmitigated" in filename:
		addOn = "unmitigated"
	elif "normalized" in filename:
		addOn = "mitigated, normalized"
	else:
		addOn = "mitigated"
	if len(filenames)==1:
		someAxes = axarr
	elif not isinstance(axarr[0], np.ndarray):
		someAxes = axarr[i]
	else:
		someAxes = np.array(flatten([axarr[:, i], axarr2[:, i]]))
		#print "someAxes: ", someAxes, "\n"
	stats.append(getInfo(filename, freq, someAxes, addOn))

f2.show()
plt.show()

# compare stats of all the files
for i in range(1, len(stats)):
	print "\n"+filenames[i]+" compared to unmitigated:\n"
	for j in range(len(stats[i])):
		print "\t"+statnames[j]+" is "+str(stats[i][j]/stats[0][j]*100)+" percent of the unmitigated value."

# exit
sys.exit(0)

bands = np.array(map(lambda x: getBand(x),freqs))
for i,band in enumerate(BANDS):
    inds = np.where(bands==band)[0]
    errorbar(mjds[inds],resids[inds],yerr=errs[inds],fmt='.',color=colors[i])
xlabel("MJD")
ylabel("Residual (us)")
show()


raise SystemExit


data = np.transpose(np.loadtxt("resids/%s_residuals.dat"%psr))
data_avg = np.transpose(np.loadtxt("resids/%s_residuals_epochavg.dat"%psr))

errorbar(data[0],data[2]*1e6,yerr=data[3],fmt='k.')
errorbar(data_avg[0],data_avg[1],yerr=data_avg[2],fmt='bo',markersize=7,zorder=100)
xlabel(r"$\mathrm{MJD}$")
ylabel(r"$\mathrm{Residual~[\mu s]}$")
show()
